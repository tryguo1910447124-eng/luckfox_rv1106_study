# 同步原语使用场景速查（内核/驱动为主）

下面把 **atomic（原子操作） / spinlock（自旋锁） / mutex（互斥锁） / semaphore（信号量）** 的语义、典型场景、优缺点和常见误用一并浓缩成表格 + 决策要点，方便你快速选择。

---

## 快览表（一句话）

* **原子操作（atomic, cmpxchg, atomic_inc...）**：用于单字/指针的无锁更新与 test-and-set、计数器，开销最小，不阻塞，适合极短操作与 IRQ-safe 场景。
* **自旋锁（spinlock / spin_lock_irqsave）**：保护非常短的临界区、可在 IRQ/atomic 上下文使用，会忙等（CPU 占用高），适合在不可睡眠的环境中。
* **互斥锁（mutex）**：可睡眠、用于较长或可能阻塞的临界区，延迟/开销较大，但代码可读性好、不会忙等。**不能**在 IRQ/持自旋锁时使用。
* **信号量（semaphore / down/up）**：用于计数资源（N 个可用资源）与可中断等待；语义上比 mutex 更偏“资源池/等待队列”。

---

## 详细说明与典型例子

### 1) 原子操作（`atomic_t`, `cmpxchg`, `atomic_inc`）

* **什么时候用**：单个整型/指针的无锁操作（计数器、flag、test-and-set），短且频繁；可在 IRQ/softirq 中使用（取决具体操作）。
* **优点**：最低开销、无阻塞、线程安全。
* **缺点**：只能处理简单的单字操作；不能保护复杂数据结构的一致性（需要屏障或组合更复杂的同步策略）。
* **示例**：

  ```c
  /* exclusive open flag */
  atomic_set(&dev->flag, 0);
  if (atomic_cmpxchg(&dev->flag, 0, 1) != 0) return -EBUSY;
  /* release: atomic_set(&dev->flag, 0); */
  ```

### 2) 自旋锁（`spinlock_t` / `spin_lock_irqsave`）

* **什么时候用**：临界区非常短、不能睡眠（例如在中断处理、bottom half、持有软中断上下文）时。
* **优点**：在不可睡眠的上下文也能同步；开销低（短期）。
* **缺点**：忙等会耗 CPU；不适合长时间操作；不能在持自旋锁时睡眠。
* **示例**：

  ```c
  unsigned long flags;
  spin_lock_irqsave(&lock, flags);
  /* quick update shared state */
  spin_unlock_irqrestore(&lock, flags);
  ```

### 3) 互斥锁（`struct mutex`）

* **什么时候用**：临界区可能较长、会进行阻塞/IO/睡眠操作时（用户态交互、alloc_wait 等）。
* **优点**：不会忙等，适合长操作；调试友好（owner info）；易用。
* **缺点**：会睡眠（上下文切换开销），**不能**在 IRQ/atomic context 使用。
* **示例**：

  ```c
  mutex_init(&m);
  mutex_lock(&m);
  /* can sleep here */
  mutex_unlock(&m);
  ```

### 4) 信号量（`struct semaphore`）

* **什么时候用**：需要管理 N 个可用资源或等待队列（比如限制并发连接数、控制资源池）。可阻塞/可中断等待。
* **优点**：天然支持计数资源与等待；语义明确。
* **缺点**：比 mutex 更复杂（历史语义），在某些场景 mutex 更合适。
* **示例**：

  ```c
  down_interruptible(&sem); /* wait */
  /* use resource */
  up(&sem);                 /* release */
  ```

---

## 决策树（快速选哪种？）

1. **当前上下文能睡眠吗？**

   * 否（IRQ/softirq/持自旋锁） → 用 **atomic**（仅单字） 或 **spinlock**（短临界区）。
   * 能 → 继续下一步。

2. **临界区会很短并频繁吗？**

   * 是 → 若可睡眠且短也可用 **spinlock**，但优先考虑 **mutex**（若不在 IRQ）。
   * 否 → 使用 **mutex**。

3. **需要计数资源（允许多个同时持有）？**

   * 是 → 用 **semaphore**（或 `atomic_t`+waitqueue 实现更复杂逻辑）。
   * 否 → 考虑 **atomic**（flag/计数器）或 **mutex**（独占）。

4. **只是对单个整型/标志做测试并设置？**

   * 用 **atomic_cmpxchg**（轻量、无锁）。

---

## 常见误区（短）

* **误把 mutex 用在 IRQ 中** → 会 BUG（不能睡眠）。
* **用自旋锁做长时间操作** → CPU 占用高，降低系统响应。
* **用原子操作来保护复杂结构** → 容易出竞态，需要更重型锁。
* **把计数器初值/语义搞错**（如 init=1 配合 dec_and_test） → 会出现负值/回滚，语义混乱。

---

## 实战建议（针对驱动开发）

* 设备“只允许一个打开者” → `atomic_cmpxchg(&flag, 0, 1)` 或 `mutex_trylock()`（如果 open 会做睡眠）。
* 在 IRQ handler 要保护共享数据 → `spin_lock_irqsave()` 或使用 `atomic`（仅单字）。
* 需要在最后一个 close 做清理 → 在 release 中用 `if (atomic_dec_and_test(&count)) { /* cleanup */ }`。
* 控制并发资源数（N 个） → `struct semaphore`（`down`/`up`）或 `classically` 用 `atomic`+waitqueue。

---

需要的话我可以把上面的决策树和示例做成一页便于打印的笔记（或把你当前驱动的 open/release/irq 代码贴上来，我按规则检查并给出“应该用哪个原语”的修改建议）。你要哪个？


# 什么是并发与竞争
    cup工作时间
        任务一开始执行 任务二正在执行 任务三执行结束 
单核cpu
          任务二开始执行 任务二 正在执行 任务二 执行结束 
    单核 在一个时间片只能执行一个任务
    比如 任务一开始执行 -任务二正在执行 -任务一正在执行 -任务二执行结束 

双核cpu，在一个cpu上可以跑一个任务 如果两个任务同时进行 就是并行 
一个cpu会执行多个任务。任务一和任务二对cpu1是并发的 cpu1和cpu2是并行 

并行是并发的理想状态  统称并发
    并发会造成多个程序同时访问一个共享资源，同时访问一个资源而产生的问题就是竞争。
    linux是一个多任务的操作系统，并发和竞争再linux上非常常见，所以编写linux驱动过程中要考虑并发和竞争。否则访问资源会出问题。
    必须处理并发与竞争 不出问题使不出问题 一出问题排查非常困难。
linux一般再以下几种情况会造成并发
    1）中断程序并发访问。中断是可以随时产生的，一旦产生中断，就会放下手头的工作，去执行终端的任务。如果再执行中断中的任务的时候修改了共享资源，就会产生并发。
    2）抢占式并发访问。linux在2.6之后，linux内核支持了抢占，在支持抢占的情况下，正在执行的进程随时都有可能被抢占。
    3）多处理器（SMP）并发访问内核。多核处理器之间存在核间并发访问。

    共享资源一般是某个整形的全局变量，或者驱动中的设备结构体。其他数据也可能是共享数据。

    处理发放一般是：原子操作，自旋锁，信号量，互斥体。

# 原子操作
    linux原子形态一个操作或者一个函数是最小的执行单位，是不可被打断的。原子操作指的是该操作在执行完之前不会被任何事物打断。
    一般用于整形变量或者位的保护。
    atomic_t 32位   atomic64_t  64位
    Linux 内核原子 API（kernel-space，atomic_t / atomic64_t 等）

        读取/写入：

        atomic_read(const atomic_t *v)

        atomic_set(atomic_t *v, int i)

        自增/自减/加/减（返回不同）：

        atomic_inc(atomic_t *v) / atomic_dec(atomic_t *v)

        atomic_add(int i, atomic_t *v) / atomic_sub(int i, atomic_t *v)

        atomic_inc_return(atomic_t *v) / atomic_dec_return(atomic_t *v)

        atomic_add_return(int i, atomic_t *v) / atomic_sub_return(int i, atomic_t *v)

        交换 / 比较交换：

        atomic_xchg(atomic_t *v, int new)（或 xchg 变体）

        atomic_cmpxchg(atomic_t *v, int old, int new)

        atomic_try_cmpxchg(atomic_t *v, int *oldp, int new)（helper）

        原子位操作、长整型/64位变体：

        atomic64_read / atomic64_set / atomic64_inc / 等

        还有 smp_mb__() / smp_wmb() / smp_rmb() 等内存屏障与架构相关原语（kernel 提供的屏障）

    原子操作举例
        atomic64_t v = ATOMIC64_INIT(0);//定义并初始化原子变量v=o
        atomic64_set(&v,1); //设置v=1
        atomic64_read(&v); //读取v的值，此时v的值为1
        atmoic64_inc(&v); //v的值加1，此时v为11

        #include <linux/atomic.h>
        #include <asm/atomic.h>
        需要包含这两个头文件。
        一般的使用场景
        短答：**对** — 在需要做“测试并置位（test-and-set）”的场景（比如只允许一个打开者）时，**用 `atomic_cmpxchg`（或通用的 `cmpxchg`）更合适**；而在需要“计数（tracking）”的场景下，才用 `atomic_inc` / `atomic_dec` 系列并结合返回值或 `atomic_dec_and_test` 来判断。两者各有语义与适用场景，不是单一替代关系。

下面把常见场景、推荐用法与示例一次给你——方便直接套用。

---

## 场景与推荐

1. **排他打开（only-one opener）—— 用 `atomic_cmpxchg` 做 test-and-set**

   * 语义：只有当值为 `0` 时把它置为 `1`，否则失败并返回 `-EBUSY`。
   * 优点：一次原子比较并写入，语义明确、不产生负值或回滚。

```c
/* init: */ 初始化要在申请设备号之后   管教映射一般放在设备创建之后。
atomic_set(&dev->open_count, 0);

/* open: exclusive */
if (atomic_cmpxchg(&dev->open_count, 0, 1) != 0)
    return -EBUSY; /* 已被占用 */

/* release: */
atomic_set(&dev->open_count, 0);
```

2. **计数多个打开（track opens）—— 用增/减并检查返回值**

   * 语义：维护打开计数，允许 N 个打开；若想限制为 1，可在 inc 后回滚。
   * 常用：`atomic_inc_return()` / `atomic_dec_and_test()`。

```c
/* init */
atomic_set(&dev->open_count, 0);

/* open: */
int n = atomic_inc_return(&dev->open_count);
if (n > 1) {          /* 如果只允许 1 个打开，回滚并失败 */
    atomic_dec(&dev->open_count);
    return -EBUSY;
}

/* release: */
if (atomic_dec_and_test(&dev->open_count)) {
    /* 最后一个 close：做清理工作 */
}
```

3. **释放端检测“最后一个”—— 很适合 `atomic_dec_and_test`**

   * 语义：在 close/release 中递减并判断是否变为 0（最后一个）。

```c
if (atomic_dec_and_test(&dev->open_count)) {
    /* last close: cleanup */
}
```

4. **更高层的替代（推荐可读性）—— 使用 mutex**

   * 如果你只是需要“互斥访问/互斥打开”，`mutex_trylock()` 更直观且功能完备：

```c
if (!mutex_trylock(&dev->lock))
    return -EBUSY;
/* release: mutex_unlock(&dev->lock) */
```

---

## 何时不用 cmpxchg 而用加减？

* 当你要表现 *“这是一个计数器”*（想知道有多少个打开者），应使用 `atomic_inc/_dec`。
* 当你要表现 *“这是一个开关/标志，只能 0/1”*（只允许一个持有者），`atomic_cmpxchg`（或 `cmpxchg`）最简洁正确。

---

## 内存可见性（提醒）

* `atomic_cmpxchg` 保证对该变量的原子修改；但若在成功置位后有其它共享数据需要被初始化并被读者看到，可能要用 acquire/release 变体或显式内存屏障（例如 `cmpxchg_acquire`/`cmpxchg_release` 或 `smp_mb()`）来保证写入顺序可见性。简单互斥标志常规用法通常够用，但复杂场景要注意内存序。

---

## 小结快速清单

* 需要“test-and-set”（排他）：`atomic_cmpxchg(&v, 0, 1)`；
* 需要“计数/统计”：`atomic_inc_return`，`atomic_dec_and_test`（在 release 检测最后一个）；
* 只要互斥且想简单可读：`mutex_trylock()` / `mutex_lock()`；
* 初始化：动态分配后 `atomic_set(&v, 0)`；静态可用 `ATOMIC_INIT(0)`。

---

要不要我把上面三种（exclusive、counting、mutex）都给你做成完整的 `open`/`release` 模板文件，方便直接复制到驱动里测试？哪种你要先看？
如果需要模板 你可以复制这个给gpt

#  自旋锁
 自旋锁是为了实现保护共享资源提出的另一种锁机制，也是内核中中比较常见的锁机制。自旋锁是以“原地等待”的方式解决资源冲突。即当线程A获得到自旋锁以后
 此时线程B也想获得到自旋锁，但是线程B获取不到，只能“原地打转”（仍然占用CPU，不会休眠）。不断尝试获取自旋锁，获取成功后，才退出循环。
 
 linux内核使用结构体spinlock_t来描述自旋锁。
 函数                          描述
DEFINE_SPINLOCK(spinlock t lock)                                         定义并初始化一个变量
int_spin_lock init(spinlock t*lock)                                      初始化自旋锁
void_spin_lock(spinlock t *lock)                                         获取自旋锁，也叫做加锁
void_spin_unlock(spinlock t *lock)int spin trylock(spinlock t *lock)     释放自旋锁，也叫做解锁
int_spin_is_locked(spinlock t **lock)                                    尝试获取自旋锁，如果没有获取到就返回0检查自旋锁是否被获取，如果没有被获取就返回非0，否则返回0

 1)在访问临界资源的时候先申请自旋锁
 2)获取到自旋锁以后就进入临界区，获取不到自旋锁就“原地等待”
 3)退出临界区的时候要释放自旋锁

    spin_lock(&spinlock);

    if (flag != 1) {
        spin_unlock(&spinlock);
        return -EBUSY;
    }
    if(flag == 1) {
        flag = 0;
    }

    spin_unlock(&spinlock);
    
1）自旋锁 锁的时间不能太长，也就是临界区的代码不能太多。
2）保护的临界区里面不能调用可能会导致线程休眠的函数，否则会发生死锁
3）自旋锁一般用在多核soc
保护了一个很小的全局变量

static int flag = 1;
static int my_cdev_open(struct inode *inode, struct file *file)
{
    spin_lock(&spinlock);

    if (flag != 1) {
        spin_unlock(&spinlock);
        return -EBUSY;
    }
    if(flag == 1) {
        flag = 0;
    }

    spin_unlock(&spinlock);
    file->private_data = &mydev;
    pr_info("mychardev: open\n");
    return 0;
}

static int my_cdev_release(struct inode *inode, struct file *file)
{
    spin_lock(&spinlock);
    flag = 1;
    spin_unlock(&spinlock);
    return 0;
}

自旋锁通过更改全局变量的值来控制访问 my_cdev_open调用时候也就是a打开会在保护区域把flag变为0 b再打开就打开不了了 除非a释放


## 下面是GPT推荐写法  
unsigned long flag=1; //业务变量，表示设备是否可用，1表示可用，0表示不可用  一定要赋初值
static int my_cdev_open(struct inode *inode, struct file *file)
{
    unsigned long flags;                /* 局部变量，保存中断标志 *///保护cpu状态的变量，目的是获取锁的时候禁用本地中断，防止死锁

    spin_lock_irqsave(&my_lock, flags); /* 保存并关本地中断 */

    if (flag != 1) {
        spin_unlock_irqrestore(&my_lock, flags);
        return -EBUSY;
    }
    flag = 0;

    spin_unlock_irqrestore(&my_lock, flags); /* 恢复中断状态 */

    file->private_data = &mydev;
    pr_info("mychardev: open\n");
    return 0;
}
static int my_cdev_release(struct inode *inode, struct file *file)
{
    unsigned long flags;

    spin_lock_irqsave(&my_lock, flags);
    flag = 1;
    spin_unlock_irqrestore(&my_lock, flags);
    return 0;
}
spin_lock_irqsave/irqrestore(会把中断进行关闭) 在可能被中断打断的场景下保护中断上下文，避免中断处理同时访问同一资源。这个函数是为了 避免中断死锁 ，具体操作请看下文
## 自旋锁的死锁
    情况1：多核cpu和支持抢占的单核cpu中，被自旋锁保护的区域(临界区)不能调用任何能够引起睡眠或者阻塞的函数，否则就会发生死锁。
    使用自旋锁会静止抢占。比如在单核cpu下，A进程获取到自旋锁之后会暂时关闭抢占，如果A进程此时进入了休眠状态（放弃了CPU的使用权），B进程此时也想获取到自旋锁，但是此时自旋锁是被A持有的，此时CPU的抢占也是被禁止了。因为是单核，进程B没办法被调度出去，只能在“原地打转”等待锁被A释放。但是进程A无法运行，锁也没办法释放。死锁就发生了。
    
    多核cpu不会发生上面的情况。因为其他的核会调度其他进程。
    
    情况2：进程A获取到自旋锁，然后在临界资源也就是保护区域中产生了中断，但是在中断里面也要访问共享资源(中断里面使用了自旋锁)，但是由于现在进程A已经把锁锁上了，并没有进行解锁，这时候中断里面就没办法获取到自旋锁，只能原地打转，就会产生死锁，这也就是为什么gpt推荐我们使用spin_lock_irqsave/irqrestore这两个API 因为这两个api在所得时候会把中断进行关闭也就是禁止中断并获取自旋锁

    下面是gpt的解释 

    你说得**基本正确** —— 核心思路没问题，但还有几个重要细节和例外需要补充说明，避免误用或理解偏差。下面我把要点分条说明，给出正确用法示例与常见陷阱。

---

### 核心结论（一句话）

* `spin_lock_irqsave()` / `spin_unlock_irqrestore()` 在抢占/进程上下文获取自旋锁时，会**禁止本 CPU 的本地中断并保存中断标志**，从而避免在同一 CPU 上被中断打断而导致中断处理程序试图再次获取相同自旋锁而自旋死锁。
* 但这只是解决“同一 CPU 上的中断与进程竞争同一把锁”的问题；**不能影响其他 CPU 上的中断**，也不能替代其它并发控制原语的语义需求（比如睡眠场景）。

---

##### 详细要点与补充

1. **为什么会死锁**

   * 场景：进程 A 在 CPU0 上持有 `spinlock`（用 `spin_lock()`），然后被中断（hard IRQ）打断；中断处理函数（在 same CPU）也尝试 `spin_lock()` 同一把锁 -> 中断会自旋等待，但进程 A 被中断并尚未释放锁 -> **死锁**（中断永远等待，锁永远不会释放）。
   * `spin_lock_irqsave()` 的作用是：在进程获取锁的同时禁用本地中断，防止本 CPU 被打断，从而避免中断处理路径在本 CPU 中再次尝试拿锁导致自旋死锁。

2. **它只影响“本地 CPU 的中断”**

   * `irqsave` 禁用的是**本 CPU 的本地中断**。如果中断在另一个 CPU 上发生，禁中断不会阻止那个中断，也不会阻止它去尝试拿锁 —— 那种情况由自旋等待/互斥正常处理（不同 CPU 自旋等待直到锁释放），**不会死锁**（除非还有其它交叉依赖的问题）。 
   * 因此 `irqsave` 的目标是防止**同 CPU** 的中断打断临界区。

3. **在中断上下文里通常不用 irqsave**

   * 在硬中断（hard IRQ）处理函数里，内核在运行中断处理时通常已经禁用了本地中断（hardware interrupt handlers run with local interrupts disabled by default），因此在 IRQ handler 中直接使用 `spin_lock()` 就足够（不过使用 `spin_lock_irqsave()` 也安全但多余）。
   * 关键是：**不要在中断处理里使用会睡眠的同步原语**（比如 `mutex_lock()` / `down_interruptible()` 等），那会 BUG。

4. **不要在持自旋锁时睡眠**

   * 自旋锁临界区必须非常短，不能调用会睡眠的函数（包括阻塞 I/O、malloc GFP_KERNEL 可能睡眠的路径等）。如果临界区会做较长工作或可能睡眠，应使用 `mutex`。

5. **软中断 / bottom half 的处理**

   * 如果竞争的是 softirq / bottom half（tasklet 或 softirq），可以用 `spin_lock_bh()` / `spin_unlock_bh()`，它会禁用本 CPU 的底半部（softirq/tasklet），但不会禁用硬中断；用于保护同时被 tasklet/进程访问的数据。

6. **示例：正确用法对照**

进程上下文（可能被中断打断）：

```c
unsigned long flags;
spin_lock_irqsave(&my_lock, flags);
/* 短小临界区：对共享数据读/写 */
shared->x = 42;
spin_unlock_irqrestore(&my_lock, flags);
```

中断处理函数（hard IRQ）：

```c
irqreturn_t my_irq_handler(int irq, void *dev_id)
{
    /* 本地中断一般已被禁用，直接加锁保护共享数据 */
    spin_lock(&my_lock);
    /* 访问 shared */
    spin_unlock(&my_lock);
    return IRQ_HANDLED;
}
```

如果是 softirq/tasklet 与进程竞争：

```c
/* 进程 */
spin_lock_bh(&my_lock);
... /* 访问 */
spin_unlock_bh(&my_lock);

/* tasklet/softirq */
spin_lock(&my_lock);   /* tasklet runs in softirq context; use matching api */
... 
spin_unlock(&my_lock);
```

7. **嵌套与一致性**

   * 加锁/解锁必须成对且匹配：不要用 `spin_lock()` 加，然后用 `spin_unlock_irqrestore()` 解（必须对称使用）。
   * 如果你用 `spin_lock_irqsave()`，解锁时必须用对应的 `spin_unlock_irqrestore()` 并传入之前保存的 `flags`。

8. **替代策略**

   * 若临界区非短或会睡眠：用 `mutex`（可睡眠）或其他更高层同步原语（workqueue 等）。
   * 若只需对单字标志做 test-and-set：优先考虑 `atomic_cmpxchg`（无须禁中断/自旋）。

---

##### 总结

你理解的**“进程拿锁被中断后中断处理再拿锁会死锁，因此要在进程拿锁时禁本地中断以避免被中断打断”**这个结论是**正确的**。
但要记住：

* `spin_lock_irqsave()` 只是解决“同一 CPU 被中断打断”的情形，不能控制其他 CPU 的中断；
* 必须配对使用 `irqsave`/`irqrestore`，并保证临界区很短且不睡眠；
* 根据场景选择更合适的 API（`spin_lock_bh`、`atomic`、`mutex` 等）。

需要的话我可以把你当前驱动里 `open/read/write/release`、以及可能的中断处理片段贴上来，我帮你改成**正确且健壮**的锁策略（例如对进程/IRQ/softirq 分别用合适的加锁方式），并指出哪些函数不能在持锁期间调用。要我帮你改哪部分？

# 信号量 #include  <linux/semaphore.h> 
   自旋锁是通过“原地等待”的方式来处理并发和竞争的，所以保护的临界区域不能太长，以免造成cpu资源的浪费。但是有时候我们必不可避免的需要长时间对一些资源进行保护，这时候就可以使用信号量。
   A可以给B说 你可与休息一会儿再来 我使用完告诉你 你再来 这个就是信号量，所以信号量也叫睡眠锁。
    1)信号量会引起调用者的休眠
    2）在持有锁的时间比较长的时候，自旋锁不适用用了，我们应该用信号量
## 信号的工作方式
    信号量的本质是一个全局变量。信号量的值可以根据实际情况来自行设置(取值范围大于等于0)，当有线程来访问资源时，信号量执行“减一”操作，访问结束之后再“加一”。
    函数                                                      描述
    DEFINE SEAMPHORE(name）                          定义信号量，并设置信号量的值为1
    void sema init(stiuet semaphore *sem, int val)  初始化信号量sem,并设置信号的值为 val
    void down(struet semaphore *sem)                    获取信号量。不能被信号打断，如ctrl+c
    int down interuptible(stiuct semaphore *sem）       获取信号量。能被信号打断，如ctrltc
    void up(struct semaphore *sem)                      释放信号  量
    int down trylock(struet semaphore *sem)             尝试获取信号量，如果获取到信号量就返回获取不到就返回非00. 

    **我们定义信号量的时候** 使用结构体semaphore 来表示信号量 定义在semaphore.h文件中。
    struct semaphore{
        raw_spinlock_t  lock;
        unsigned int count;
        struct list_head wait_list;
    };

    好——直接说重点并给出可拷贝的示例代码与注意事项。

### 核心区别（一句话）

* `down(&sem)`：**不可中断阻塞**，在等待时进程状态为不可中断（TASK_UNINTERRUPTIBLE），信号不会打断等待。
* `down_interruptible(&sem)`：**可中断阻塞**，在等待时进程状态为可中断（TASK_INTERRUPTIBLE），如果收到信号会立即返回（不再等待），返回值非 0 表示被信号中断。

### 为什么在 `open()` 更常用 `down_interruptible()`？

1. **用户体验 / 可杀性**：`open()` 是用户态触发的系统调用，若它在等待资源时不可中断（`down()`），用户无法用 Ctrl-C、kill 等中断操作将其杀掉，可能导致不可杀死的进程或糟糕的交互体验。`down_interruptible()` 允许用户中断等待，使得进程能被杀或能响应信号。
2. **遵循惯例**：内核里面向用户的阻塞通常使用“可中断”的版本（例如 `mutex_lock_interruptible()`），以便 syscall 可被信号中断并适当地返回错误给用户层。
3. **易于处理错误路径**：用可中断版本可以在返回时做清理并返回合适的错误码给用户。

### 返回值与用户 errno 的映射

* `down_interruptible()` 在被信号打断时返回非 0（通常  -ERESTARTSYS / -EINTR 由你代码决定如何返回给用户）。
* 内核驱动通常在 open 中写成：

```c
if (down_interruptible(&sem))
    return -ERESTARTSYS;  /* 推荐：使 syscall 可被 restart 或返回 EINTR 给用户 */
```

`-ERESTARTSYS` 是内核里常用的返回值，表示系统调用被信号中断，可由内核决定是否重启。

### 什么时候会用 `down()`（不可中断）？

* 在内核内部并且**必须**保证资源最终被获取且等待不可被中断的场景（非常少见），或用于某些驱动内部逻辑，你明确不希望被信号打断。但要小心会导致不可杀死的进程。

### 非阻塞 / 支持 O_NONBLOCK 的处理

如果用户以非阻塞方式打开设备，应马上返回而不是阻塞，常用 `down_trylock()`：

```c
if (file->f_flags & O_NONBLOCK) {
    if (!down_trylock(&sem))
        return -EAGAIN; /* 资源暂不可用，非阻塞返回 */
} else {
    if (down_interruptible(&sem))
        return -ERESTARTSYS;
}
```

### mutex 的可中断版本

如果你改用 `struct mutex`，类似地有 `mutex_lock_interruptible()` 可用，逻辑与 `down_interruptible` 类似：

```c
if (mutex_lock_interruptible(&my_mutex))
    return -ERESTARTSYS;
```

通常 mutex 更适合普通互斥（且 API 更现代）。

### 完整 `open/release` 推荐模板（包含 O_NONBLOCK）

```c
static struct semaphore sem;

static int my_cdev_open(struct inode *inode, struct file *file)
{
    /* 非阻塞支持 */
    if (file->f_flags & O_NONBLOCK) {
        if (!down_trylock(&sem))
            return -EAGAIN;
    } else {
        if (down_interruptible(&sem))
            return -ERESTARTSYS;
    }

    file->private_data = &mydev;
    pr_info("mychardev: open success\n");
    return 0;
}

static int my_cdev_release(struct inode *inode, struct file *file)
{
    up(&sem);
    pr_info("mychardev: release\n");
    return 0;
}

static int __init my_init(void)
{
    sema_init(&sem, 1);
    ...
}
```

### 其他重要注意点

* **不要在 IRQ/atomic 上下文或持自旋锁时调用 `down_*()`**（会睡眠，内核会 BUG）。
* 使用 `down_interruptible()` 要注意处理好返回路径，避免资源泄露（比如在 open 部分做了部分初始化，后来被信号打断时要回滚）。
* `down_trylock()` 是非阻塞的好选择，但它只做一次尝试（立即返回成功或失败）。

---

总结：对于用户触发的 `open()`，**优先使用 `down_interruptible()`（或 mutex 的 interruptible 版本）并支持 O_NONBLOCK**；只有在明确需要不可中断等待的内核内部逻辑上才考虑 `down()`。需要我把你现有模块改成上面模板并加入错误回滚/日志的吗？
down(&sem)
语义：阻塞地获取信号量，不可中断。
若 sem 当前计数 > 0：立即把计数原子地减 1，并返回（成功）。
若 sem 当前计数 == 0：进程进入不可中断等待，直到有 up() 使其被唤醒并获取（并把计数减 1）。
返回值：无（通常没有错误返回），调用后一定成功获取到信号量（除非内核BUG）。
down_interruptible(&sem)
语义：阻塞地获取信号量，可被信号中断。
若 sem 当前计数 > 0：立即把计数原子地减 1，并返回 0（成功）。
若 sem 当前计数 == 0：进程进入可中断等待；若在等待期间收到信号，会停止等待并返回非 0（表示被中断），此时未获取到信号量，计数并未被减。如果被唤醒并成功获取，则像 down() 一样将计数减 1 并返回 0。
返回值：0 表示成功获取；非 0 表示被信号中断（调用者应处理）。
down_trylock(&sem)：非阻塞尝试，若计数>0 则减1并返回 true；否则立即返回 false（不阻塞，也不改变计数）。

### 模板gpt

static struct semaphore sem;   
static int my_cdev_open(struct inode *inode, struct file *file)
{
    /* 非阻塞支持 */
    if (file->f_flags & O_NONBLOCK) {
        if (!down_trylock(&sem))
            return -EAGAIN;
    } else {
        if (down_interruptible(&sem))
            return -ERESTARTSYS;
    }

    file->private_data = &mydev;
    pr_info("mychardev: open success\n");
    return 0;
}

static int my_cdev_release(struct inode *inode, struct file *file)
{
    up(&sem);
    pr_info("mychardev: release\n");
    return 0;
}

static int __init my_init(void)
{
    sema_init(&sem, 1); //内核用的是seam
    ...
}

#### 注意事项

信号量的注意事项
1.信号量的值不能小于0
2.访问共享资源时，信号量执行“减一”操作，访问完成后在执行“加一”操作
3.当信号量的值为0时，想访问共享资源的线程必须等待，直到信号量大于0时，等待的线程才可以访间
4.因为信号量会引起休眠，所以中断里面不能用信号量
5.共享资源持有时间比较长，一般用信号量而不用自旋锁
6.在同时使用信号量和自旋锁的时候，要先获取信号量，再使用自旋锁。因为信号量会导致睡眠。


# 互斥锁  #include <linux/mutex.h>
    同一个资源同一个时间只有一个访问者在进行访问，其他的访问者访问结束以后才可以访问这个资源，这就是互斥。
    互斥锁和信号量值为1的情况很类似，但是互斥锁更简洁。不过需要注意的事项也更多。
    
struct mutex {
	atomic_long_t		owner;
	spinlock_t		wait_lock;
#ifdef CONFIG_MUTEX_SPIN_ON_OWNER
	struct optimistic_spin_queue osq; /* Spinner MCS lock */
#endif
	struct list_head	wait_list;
#ifdef CONFIG_DEBUG_MUTEXES
	void			*magic;
#endif
#ifdef CONFIG_DEBUG_LOCK_ALLOC
	struct lockdep_map	dep_map;
#endif
	ANDROID_OEM_DATA_ARRAY(1, 2);
};


函数                                        描述
DEFINE_MUTEX(name)                          定义并初始化一个互斥锁
void_mutex_init(mutex *lock)                初始化互斥锁
void_mutex_lock(struct mutex *lock)         上锁，如果不可以用则睡眠
void_mutex_unlock(struct mutex *lock)       解锁
int mutex_is_locked(struct mutex *lock)     如果锁已经被使用则返回1，否则返回0


## 互斥锁的注意事项
1）互斥锁会导致休眠，所以在中断里面不能用互斥锁。
2）同一时刻只能有一个线程持有互斥锁，并且只有持有者可以解锁。
3）不允许递归上锁和解锁(一个函数用的时候上锁 出函数解锁 不能再open上锁 release上解锁)。

使用信号量和互斥锁都可以的时候，优先使用互斥锁。
不要在 open() 中长期持有 mutex（直到 release() 才释放），因为会导致同一线程在后续的 read/write 中自死锁且阻塞其他内核路径。


#include <linux/mutex.h>
/* 推荐静态初始化（不需要在 init 中再调用 mutex_init） */
static DEFINE_MUTEX(mutexlock);

static int flag = 1; /* 1 = 可用, 0 = 被占用 */

static int my_cdev_open(struct inode *inode, struct file *file)
{
    /* 支持非阻塞打开 */
    if (file->f_flags & O_NONBLOCK) {
        if (!mutex_trylock(&mutexlock))
            return -EAGAIN;   /* 非阻塞且资源不可用 */
    } else {
        /* 可被信号中断的获取，避免不可杀死的阻塞 */
        if (mutex_lock_interruptible(&mutexlock))
            return -ERESTARTSYS;
    }

    if (flag != 1) {
        mutex_unlock(&mutexlock);
        return -EBUSY;
    }
    flag = 0; /* 占用 */

    mutex_unlock(&mutexlock);

    file->private_data = &mydev;
    pr_info("mychardev: open success\n");
    return 0;
}

static int my_cdev_release(struct inode *inode, struct file *file)
{
    mutex_lock(&mutexlock);
    flag = 1; /* 释放 */
    mutex_unlock(&mutexlock);

    pr_info("mychardev: release\n");
    return 0;
}

后面如果需要的话 可以把信号量写道结构体当中 其实 我现在已经把读写互斥锁写到了 结构体当中 。



// 字符设备驱动框架 - 稳健版（含并发与越界处理）
#include <linux/module.h>
#include <linux/init.h>
#include <linux/moduleparam.h>
#include <linux/fs.h>
#include <linux/kdev_t.h>
#include <linux/types.h>
#include <linux/cdev.h>
#include <linux/device.h>     // class_create, device_create
#include <linux/uaccess.h>    // copy_to_user, copy_from_user
#include <linux/mutex.h>
#include <linux/string.h>
#include <linux/atomic.h>
#include <asm/atomic.h>
#include  <linux/semaphore.h>

MODULE_LICENSE("GPL");
MODULE_AUTHOR("Luckfox");
MODULE_VERSION("V1.2");
MODULE_DESCRIPTION("A simple and robust char device driver");


// 模块参数：从哪个次设备号开始分配（单设备时保持为 0 即可）
static int minor = 0;
module_param(minor, int, 0644);
MODULE_PARM_DESC(minor, "First minor number of the device");

#define KBUF_SIZE 100

struct mydev_t {
    dev_t dev_num;            // 设备号
    struct cdev cdev;         // 字符设备对象
    struct class *cls;        // /sys/class 下的类
    struct device *dev;       // /dev 下的设备节点
    char   kbuf[KBUF_SIZE];   // 内核缓冲
    size_t datalen;           // 有效数据长度
    struct mutex lock;        // 并发保护
    
};

static struct mydev_t mydev;

static struct mutex mutexlock; //定义互斥锁
static int flag = 1; //业务变量，表示设备是否可用，1表示可用，0表示不可用

/* ------------ file operations ------------ */

static int my_cdev_open(struct inode *inode, struct file *file)
{
    /* 支持非阻塞打开 */
    if (file->f_flags & O_NONBLOCK) {
        if (!mutex_trylock(&mutexlock))
            return -EAGAIN;   /* 非阻塞且资源不可用 */
    } else {
        /* 可被信号中断的获取，避免不可杀死的阻塞 */
        if (mutex_lock_interruptible(&mutexlock))
            return -ERESTARTSYS;
    }

    if (flag != 1) {
        mutex_unlock(&mutexlock);
        return -EBUSY;
    }
    flag = 0; /* 占用 */

    mutex_unlock(&mutexlock);

    file->private_data = &mydev;
    pr_info("mychardev: open success\n");
    return 0;
}

static ssize_t my_cdev_read(struct file *file, char __user *buf, size_t size, loff_t *off)
{
    // size_t size 用户请求读取最大的字节数 loff_t *off 文件偏移量  
    struct mydev_t *d = file->private_data; //open的时候把结构体类型为mydev_t的 mydev地址传进来现在取出来以便访问设备缓冲状态
    ssize_t ret = 0;

    mutex_lock(&d->lock);//加锁，防止并发读写引起数据混乱

    // EOF：偏移 >= 数据长度    如果偏移量已经到达或超过了数据长度，说明没有更多数据可读，返回0表示EOF
    if (*off >= d->datalen) {
        ret = 0;
        goto out;
    }

    // 限幅：最多读剩余的 用户请求读取的字节数不能超过剩余的数据长度
    if (size > d->datalen - *off)
        size = d->datalen - *off;

    if (copy_to_user(buf, d->kbuf + *off, size)) {
        ret = -EFAULT;
        goto out;
    }

    *off += size;//文件偏移本次实际读取的字节数 下一次不不会重复读取
    ret = size;

    pr_info("mychardev: read %zd bytes, new pos=%lld\n", ret, *off);

out:
    mutex_unlock(&d->lock);
    return ret;
}

static ssize_t my_cdev_write(struct file *file, const char __user *buf, size_t size, loff_t *off)
{
    struct mydev_t *d = file->private_data;
    size_t space, n;
    ssize_t ret = 0;

    mutex_lock(&d->lock);

    // 不支持在缓冲区末尾之外写入 越界位置检查 如果偏移量大于缓冲区大小，说明写入位置越界，返回错误
    if (*off > KBUF_SIZE) {
        ret = -EINVAL;
        goto out;
    }
    // 计算剩余空间 space 是从当前偏移到缓冲区末尾还能写的字节数。
    space = KBUF_SIZE - *off;
    if (space == 0) {
        ret = -ENOSPC;
        goto out;
    }

    // 实际可写字节  计算本次实际可写字节数 两者取小值
    n = (size > space) ? space : size;

    if (copy_from_user(d->kbuf + *off, buf, n)) {
        ret = -EFAULT;
        goto out;
    }

    *off += n;
    if (*off > d->datalen)
        d->datalen = *off;

    ret = n;

    // 用十六进制打印写入内容（避免字符串未终止导致的越界打印）
    pr_info("mychardev: wrote %zd bytes, new pos=%lld, data(hex, first %zuB): %*phN\n",
            ret, *off, (size_t)min_t(size_t, n, 32), (int)min_t(size_t, n, 32), d->kbuf + (*off - n));

out:
    mutex_unlock(&d->lock);
    return ret;
}

static int my_cdev_release(struct inode *inode, struct file *file)
{
    mutex_lock(&mutexlock);
    flag = 1; /* 释放 */
    mutex_unlock(&mutexlock);

    pr_info("mychardev: release\n");
    return 0;
}
static const struct file_operations fops = {
    .owner   = THIS_MODULE,
    .open    = my_cdev_open,
    .read    = my_cdev_read,
    .write   = my_cdev_write,
    .release = my_cdev_release,
    .llseek  = no_llseek,  // 禁用 lseek，避免 off 被任意修改引发错位/溢出
};

/* ------------ init / exit ------------ */

static int __init modulecdev_init(void)
{
    int ret;

    // 1) 分配设备号（主设备号动态、次设备号从参数 minor 开始）
    ret = alloc_chrdev_region(&mydev.dev_num, minor, 1, "mychardev");
    if (ret) {
        pr_err("alloc_chrdev_region failed: %d\n", ret);
        return ret;
    }
    pr_info("Allocated: major=%d minor=%d\n", MAJOR(mydev.dev_num), MINOR(mydev.dev_num));

    // 初始化内部状态 分配设备号之后进行初始状态的初始化
    mutex_init(&mydev.lock);
    mydev.datalen = 0;
    mutex_init(&mutexlock);
 

    // 可选：给一个初始读出的内容
    {
        const char *hello = "Hello from kernel space! this is my_cdev_read\n";
        size_t hl = strnlen(hello, KBUF_SIZE);
        memcpy(mydev.kbuf, hello, hl);
        mydev.datalen = hl;
    }

    // 2) 初始化并注册 cdev
    cdev_init(&mydev.cdev, &fops);
    ret = cdev_add(&mydev.cdev, mydev.dev_num, 1);
    if (ret) {
        pr_err("cdev_add failed: %d\n", ret);
        goto err_unregister;
    }

    // 3) 创建 class
    mydev.cls = class_create(THIS_MODULE, "mychardev_class");
    if (IS_ERR(mydev.cls)) {
        ret = PTR_ERR(mydev.cls);
        pr_err("class_create failed: %d\n", ret);
        mydev.cls = NULL;
        goto err_cdev_del;
    }

    // 4) 创建设备节点：/dev/mychardev<minor>
    mydev.dev = device_create(mydev.cls, NULL, mydev.dev_num, NULL,
                              "mychardev%d", MINOR(mydev.dev_num));
    if (IS_ERR(mydev.dev)) {
        ret = PTR_ERR(mydev.dev);
        pr_err("device_create failed: %d\n", ret);
        mydev.dev = NULL;
        goto err_class_destroy;
    }

    pr_info("mychardev: init OK\n");
    return 0;

err_class_destroy:
    class_destroy(mydev.cls);
    mydev.cls = NULL;
err_cdev_del:
    cdev_del(&mydev.cdev);
err_unregister:
    unregister_chrdev_region(mydev.dev_num, 1);
    return ret;
}

static void __exit modulecdev_exit(void)
{
    //一定要逆序释放
    if (mydev.dev) {
        device_destroy(mydev.cls, mydev.dev_num);
        mydev.dev = NULL;
        pr_info("Device destroyed\n");
    }
    if (mydev.cls) {
        class_destroy(mydev.cls);
        mydev.cls = NULL;
        pr_info("Class destroyed\n");
    }
    cdev_del(&mydev.cdev);
    unregister_chrdev_region(mydev.dev_num, 1);
    pr_info("cdev deleted and region unregistered\n");
}

module_init(modulecdev_init);
module_exit(modulecdev_exit);
可以看出来 我其实定义了两个锁 一个锁在结构体里面控制读写 另一个锁 是全局变量

# 总结
    ![alt text](image.png)
    自旋锁 是短时间的枷锁 比如中断 、
    信号量可以保护多个资源  中断中不可以用信号量
    互斥体  信号量1和互斥体 优先用互斥体 